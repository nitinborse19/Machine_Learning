{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-03</th>\n",
       "      <td>325.25</td>\n",
       "      <td>332.83</td>\n",
       "      <td>324.97</td>\n",
       "      <td>663.59</td>\n",
       "      <td>7,380,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-04</th>\n",
       "      <td>331.27</td>\n",
       "      <td>333.87</td>\n",
       "      <td>329.08</td>\n",
       "      <td>666.45</td>\n",
       "      <td>5,749,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-05</th>\n",
       "      <td>329.83</td>\n",
       "      <td>330.75</td>\n",
       "      <td>326.89</td>\n",
       "      <td>657.21</td>\n",
       "      <td>6,590,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-06</th>\n",
       "      <td>328.34</td>\n",
       "      <td>328.77</td>\n",
       "      <td>323.68</td>\n",
       "      <td>648.24</td>\n",
       "      <td>5,405,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-09</th>\n",
       "      <td>322.04</td>\n",
       "      <td>322.29</td>\n",
       "      <td>309.46</td>\n",
       "      <td>620.76</td>\n",
       "      <td>11,688,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close      Volume\n",
       "Date                                                  \n",
       "2012-01-03  325.25  332.83  324.97  663.59   7,380,500\n",
       "2012-01-04  331.27  333.87  329.08  666.45   5,749,400\n",
       "2012-01-05  329.83  330.75  326.89  657.21   6,590,300\n",
       "2012-01-06  328.34  328.77  323.68  648.24   5,405,900\n",
       "2012-01-09  322.04  322.29  309.46  620.76  11,688,800"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"C:\\\\Users\\\\Krishna\\\\Desktop\\\\dataset\\\\Google_Stock_Price_Train.csv\",parse_dates=[\"Date\"],index_col=\"Date\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=train[[\"Open\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc=MinMaxScaler()\n",
    "sc_xtrain=sc.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1258"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sc_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_transform(n_steps,data):\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(n_steps,len(data)):\n",
    "        x.append(data[i-n_steps:i,0])\n",
    "        y.append(data[i,0])\n",
    "    return np.array(x),np.array(y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=feature_transform(n_steps,sc_xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1246, 12), (1246,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape #rows,steps,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape((x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM\n",
    "model=Sequential()\n",
    "model.add(LSTM(50,activation=\"relu\",input_shape=(n_steps,1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mean_squared_error\",optimizer=\"adam\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42/42 [==============================] - 4s 10ms/step - loss: 0.1620\n",
      "Epoch 2/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.0035\n",
      "Epoch 3/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 0.0011\n",
      "Epoch 4/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 7.5929e-04\n",
      "Epoch 5/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 8.3994e-04\n",
      "Epoch 6/100\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 6.4886e-04\n",
      "Epoch 7/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 7.1718e-04\n",
      "Epoch 8/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 6.9713e-04\n",
      "Epoch 9/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 6.6690e-04\n",
      "Epoch 10/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 8.3541e-04\n",
      "Epoch 11/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 7.9941e-04\n",
      "Epoch 12/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 5.8757e-04\n",
      "Epoch 13/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 6.0928e-04\n",
      "Epoch 14/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 6.2495e-04\n",
      "Epoch 15/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 7.5681e-04\n",
      "Epoch 16/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 5.4023e-04\n",
      "Epoch 17/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 6.5756e-04\n",
      "Epoch 18/100\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 5.8583e-04\n",
      "Epoch 19/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 5.7824e-04\n",
      "Epoch 20/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 5.3675e-04: 0s - loss: 4.962\n",
      "Epoch 21/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 5.5931e-04\n",
      "Epoch 22/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 5.4862e-04\n",
      "Epoch 23/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 6.3786e-04\n",
      "Epoch 24/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 4.3949e-04\n",
      "Epoch 25/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 4.1824e-04\n",
      "Epoch 26/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 4.3597e-04\n",
      "Epoch 27/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 4.7319e-04\n",
      "Epoch 28/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 4.3446e-04\n",
      "Epoch 29/100\n",
      "42/42 [==============================] - 0s 10ms/step - loss: 4.9567e-04\n",
      "Epoch 30/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 5.3103e-04\n",
      "Epoch 31/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 4.5972e-04\n",
      "Epoch 32/100\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 3.9983e-04\n",
      "Epoch 33/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 4.6530e-04\n",
      "Epoch 34/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 4.2235e-04\n",
      "Epoch 35/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 3.4282e-04\n",
      "Epoch 36/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 5.1589e-04\n",
      "Epoch 37/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 4.0174e-04\n",
      "Epoch 38/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.9963e-04\n",
      "Epoch 39/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 4.0236e-04\n",
      "Epoch 40/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 4.6595e-04\n",
      "Epoch 41/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 4.1869e-04\n",
      "Epoch 42/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 3.5606e-04\n",
      "Epoch 43/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 4.0272e-04\n",
      "Epoch 44/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 3.7663e-04\n",
      "Epoch 45/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.7879e-04\n",
      "Epoch 46/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.8635e-04\n",
      "Epoch 47/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 4.1420e-04\n",
      "Epoch 48/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 4.1632e-04\n",
      "Epoch 49/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 5.1103e-04: 0s - loss: 5.\n",
      "Epoch 50/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.1685e-04\n",
      "Epoch 51/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.6951e-04\n",
      "Epoch 52/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.6017e-04\n",
      "Epoch 53/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 4.5614e-04\n",
      "Epoch 54/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.3853e-04\n",
      "Epoch 55/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.9341e-04\n",
      "Epoch 56/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.4618e-04\n",
      "Epoch 57/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.8850e-04\n",
      "Epoch 58/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 4.6887e-04\n",
      "Epoch 59/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.7619e-04\n",
      "Epoch 60/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.1694e-04\n",
      "Epoch 61/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.1667e-04\n",
      "Epoch 62/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.4807e-04\n",
      "Epoch 63/100\n",
      "42/42 [==============================] - ETA: 0s - loss: 3.4395e-0 - 1s 14ms/step - loss: 3.4505e-04\n",
      "Epoch 64/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.4714e-04\n",
      "Epoch 65/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 3.6768e-04: 0s - loss: 3\n",
      "Epoch 66/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 3.6518e-04\n",
      "Epoch 67/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 3.5501e-04\n",
      "Epoch 68/100\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 3.0008e-04\n",
      "Epoch 69/100\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 3.6204e-04\n",
      "Epoch 70/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 3.6481e-04\n",
      "Epoch 71/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.8899e-04\n",
      "Epoch 72/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.4187e-04\n",
      "Epoch 73/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 3.3138e-04: 0s - loss: 3.00\n",
      "Epoch 74/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.6834e-04\n",
      "Epoch 75/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 3.1037e-04\n",
      "Epoch 76/100\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 3.7529e-04\n",
      "Epoch 77/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 2.7003e-04\n",
      "Epoch 78/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 3.0431e-04\n",
      "Epoch 79/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.0060e-04\n",
      "Epoch 80/100\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 2.9724e-04\n",
      "Epoch 81/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.4493e-04\n",
      "Epoch 82/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.3501e-04\n",
      "Epoch 83/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.8842e-04\n",
      "Epoch 84/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.0990e-04\n",
      "Epoch 85/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.5875e-04\n",
      "Epoch 86/100\n",
      "42/42 [==============================] - 1s 14ms/step - loss: 3.3345e-04\n",
      "Epoch 87/100\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 4.0758e-04\n",
      "Epoch 88/100\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 2.9678e-04\n",
      "Epoch 89/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 3.3779e-04\n",
      "Epoch 90/100\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 3.4234e-04\n",
      "Epoch 91/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.7578e-04\n",
      "Epoch 92/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 2.8853e-04\n",
      "Epoch 93/100\n",
      "42/42 [==============================] - 1s 13ms/step - loss: 2.4137e-04\n",
      "Epoch 94/100\n",
      "42/42 [==============================] - 1s 12ms/step - loss: 3.0548e-04\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 12ms/step - loss: 2.4448e-04\n",
      "Epoch 96/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 2.9125e-04\n",
      "Epoch 97/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 3.1389e-04\n",
      "Epoch 98/100\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.5000e-04\n",
      "Epoch 99/100\n",
      "42/42 [==============================] - 0s 11ms/step - loss: 4.0988e-04\n",
      "Epoch 100/100\n",
      "42/42 [==============================] - 0s 12ms/step - loss: 2.9665e-04\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=100,batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29b069ab1c0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>778.81</td>\n",
       "      <td>789.63</td>\n",
       "      <td>775.80</td>\n",
       "      <td>786.14</td>\n",
       "      <td>1,657,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>788.36</td>\n",
       "      <td>791.34</td>\n",
       "      <td>783.16</td>\n",
       "      <td>786.90</td>\n",
       "      <td>1,073,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>786.08</td>\n",
       "      <td>794.48</td>\n",
       "      <td>785.02</td>\n",
       "      <td>794.02</td>\n",
       "      <td>1,335,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>795.26</td>\n",
       "      <td>807.90</td>\n",
       "      <td>792.20</td>\n",
       "      <td>806.15</td>\n",
       "      <td>1,640,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>806.40</td>\n",
       "      <td>809.97</td>\n",
       "      <td>802.83</td>\n",
       "      <td>806.65</td>\n",
       "      <td>1,272,400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low   Close     Volume\n",
       "Date                                                 \n",
       "2017-01-03  778.81  789.63  775.80  786.14  1,657,300\n",
       "2017-01-04  788.36  791.34  783.16  786.90  1,073,000\n",
       "2017-01-05  786.08  794.48  785.02  794.02  1,335,200\n",
       "2017-01-06  795.26  807.90  792.20  806.15  1,640,200\n",
       "2017-01-09  806.40  809.97  802.83  806.65  1,272,400"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"C:\\\\Users\\\\Krishna\\\\Desktop\\\\dataset\\\\Google_Stock_Price_Test.csv\",parse_dates=[\"Date\"],index_col=\"Date\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=test[[\"Open\"]]\n",
    "sc_xtest=sc.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,y_test=feature_transform(n_steps,sc_xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=x_test.reshape((x_test.shape[0],x_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=sc.inverse_transform(ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[805.3816 ],\n",
       "       [806.0968 ],\n",
       "       [806.6634 ],\n",
       "       [814.5997 ],\n",
       "       [820.50366],\n",
       "       [824.78656],\n",
       "       [827.01404],\n",
       "       [817.49365]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=sc.inverse_transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is : 181.26669922645286\n",
      "RMSE: 13.46353219725243\n"
     ]
    }
   ],
   "source": [
    "mse=mean_squared_error(y_test.flatten(),prediction.flatten())\n",
    "print(\"MSE is :\",mse)\n",
    "print(\"RMSE:\",np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
