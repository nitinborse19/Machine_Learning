{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Poject Step by Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Model_accuracy\n",
    "#2. Best_model\n",
    "#3.Best_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare multiple models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\"LogisticRegression\":LogisticRegression(),\"DecisionTreeClassifier\":DecisionTreeClassifier(),\"SVM\":SVC()\n",
    "        ,\"KNN\":KNeighborsClassifier(),\"GNB\":GaussianNB(),\"RandomForestClassifier\":RandomForestClassifier(),\n",
    "       \"AdaBoostClassifier\":AdaBoostClassifier(),\"GradientBoostingClassifier\":GradientBoostingClassifier(),\n",
    "       \"XGBClassifier\":XGBClassifier()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for training the multiple models and generating accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelAccuracy-> models,x,y,scaleFlag=0,1,2\n",
    "def modelAccuracy(models,x,y,scaleFlag):\n",
    "    xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "    acc_result={}\n",
    "    for name,model in models.items():\n",
    "        if(scaleFlag==1):\n",
    "            model_pipeline=Pipeline([(\"MinMax\",MinMaxScaler()),('model',model)])\n",
    "        elif(scaleFlag==2):\n",
    "            model_pipeline=Pipeline([(\"standardScaler\",StandardScaler()),('model',model)])\n",
    "        else:\n",
    "            model_pipeline=Pipeline([('model',model)])\n",
    "        #model train and prediction\n",
    "        model_fit=model_pipeline.fit(xtrain,ytrain)\n",
    "        ypred=model_fit.predict(xtest)\n",
    "        acc=accuracy_score(ytest,ypred)\n",
    "        print(\"The Accuracy for \",name,\" is :\",acc)\n",
    "        acc_result[name]=acc\n",
    "    return acc_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for getting a model with highest accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestModel(model_result):\n",
    "    high=0\n",
    "    for name,acc in model_result.items():\n",
    "        if acc>high:\n",
    "            high=acc\n",
    "            model_name=name\n",
    "    print(\"Best model is \",model_name,\" with Accuracy \",high)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for getting a best models best parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParameter(model,params,x,y):\n",
    "    cv=RepeatedStratifiedKFold(n_splits=10,n_repeats=3)\n",
    "    grid_cv=GridSearchCV(estimator=model,param_grid=params,cv=cv,scoring=\"accuracy\")\n",
    "    res=grid_cv.fit(x,y)\n",
    "    print(\"Best Parameters are \",res.best_params_)\n",
    "    print(\"Best Accuracy is \",res.best_score_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data to find out suitable model for this classification dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../Data/sonar.all-data.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "     ..\n",
       "56    0\n",
       "57    0\n",
       "58    0\n",
       "59    0\n",
       "60    0\n",
       "Length: 61, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "df[60]=le.fit_transform(df[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(columns=[60])\n",
    "y=df[60]\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy for  LogisticRegression  is : 0.8333333333333334\n",
      "The Accuracy for  DecisionTreeClassifier  is : 0.6904761904761905\n",
      "The Accuracy for  SVM  is : 0.7857142857142857\n",
      "The Accuracy for  KNN  is : 0.7857142857142857\n",
      "The Accuracy for  GNB  is : 0.6666666666666666\n",
      "The Accuracy for  RandomForestClassifier  is : 0.8571428571428571\n",
      "The Accuracy for  AdaBoostClassifier  is : 0.8809523809523809\n",
      "The Accuracy for  GradientBoostingClassifier  is : 0.9047619047619048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:16:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The Accuracy for  XGBClassifier  is : 0.8809523809523809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "acc=modelAccuracy(models,x,y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': 0.8333333333333334,\n",
       " 'DecisionTreeClassifier': 0.6904761904761905,\n",
       " 'SVM': 0.7857142857142857,\n",
       " 'KNN': 0.7857142857142857,\n",
       " 'GNB': 0.6666666666666666,\n",
       " 'RandomForestClassifier': 0.8571428571428571,\n",
       " 'AdaBoostClassifier': 0.8809523809523809,\n",
       " 'GradientBoostingClassifier': 0.9047619047619048,\n",
       " 'XGBClassifier': 0.8809523809523809}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is  GradientBoostingClassifier with Accuracy  0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "bestModel(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters are  {'learning_rate': 0.5, 'loss': 'deviance', 'n_estimators': 100}\n",
      "Best Accuracy is  0.8337009803921569\n"
     ]
    }
   ],
   "source": [
    "model=GradientBoostingClassifier()\n",
    "params={\"loss\":['deviance', 'exponential'],\"learning_rate\":[0.3,0.1,0.5,0.001,0.01,0.05],\"n_estimators\":[10,50,100]}\n",
    "bestParameter(model,params,xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retraining The model using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retraining The model using best parameters\n",
    "model=GradientBoostingClassifier(learning_rate=0.5, loss='deviance',n_estimators= 100)\n",
    "model.fit(xtrain,ytrain)\n",
    "ypred=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of Best Model on testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is : 0.9047619047619048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        21\n",
      "           1       0.90      0.90      0.90        21\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.90      0.90      0.90        42\n",
      "weighted avg       0.90      0.90      0.90        42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Accuracy is :\",accuracy_score(ytest,ypred))\n",
    "print(classification_report(ytest,ypred))\n",
    "cm=confusion_matrix(ytest,ypred)\n",
    "sns.heatmap(cm,annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
